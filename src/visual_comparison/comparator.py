"""
è§†è§‰æ¯”å¯¹å™¨æ¨¡å—
Visual Comparator Module
"""
import os
import time
import gc
import psutil
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import imagehash
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import json
from datetime import datetime

from ..utils.logger import get_logger
from ..utils.asset_url_converter import convert_diff_image_path, ensure_file_exists

logger = get_logger(__name__)

@dataclass
class ComparisonResult:
    """æ¯”å¯¹ç»“æœæ•°æ®ç±»"""
    similarity_score: float  # ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
    mse_score: float        # å‡æ–¹è¯¯å·®
    ssim_score: float       # ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°
    hash_distance: int      # æ„ŸçŸ¥å“ˆå¸Œè·ç¦»
    differences_count: int   # å·®å¼‚ç‚¹æ•°é‡
    diff_image_path: str    # å·®å¼‚å›¾åƒè·¯å¾„
    analysis: Dict          # è¯¦ç»†åˆ†æç»“æœ

class VisualComparator:
    """è§†è§‰æ¯”å¯¹å™¨"""
    
    # å›¾åƒå¤„ç†é™åˆ¶
    MAX_IMAGE_DIMENSION = 2048  # æœ€å¤§å›¾åƒå°ºå¯¸
    MAX_MEMORY_MB = 512  # æœ€å¤§å†…å­˜ä½¿ç”¨(MB)
    
    def __init__(self):
        """åˆå§‹åŒ–æ¯”å¯¹å™¨"""
        self.process = psutil.Process()
        
    def _log_memory_usage(self, stage: str):
        """è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory_info = self.process.memory_info()
        memory_mb = memory_info.rss / 1024 / 1024
        logger.info(f"[{stage}] å†…å­˜ä½¿ç”¨: {memory_mb:.1f} MB")
        
        if memory_mb > self.MAX_MEMORY_MB:
            logger.warning(f"å†…å­˜ä½¿ç”¨è¶…è¿‡é™åˆ¶ ({memory_mb:.1f} MB > {self.MAX_MEMORY_MB} MB)")
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
    
    def _optimize_image_size(self, image: np.ndarray, max_dimension: int = None) -> np.ndarray:
        """ä¼˜åŒ–å›¾åƒå°ºå¯¸ä»¥å‡å°‘å†…å­˜ä½¿ç”¨"""
        if max_dimension is None:
            max_dimension = self.MAX_IMAGE_DIMENSION
            
        height, width = image.shape[:2]
        
        # å¦‚æœå›¾åƒå°ºå¯¸è¶…è¿‡é™åˆ¶ï¼Œè¿›è¡Œç¼©æ”¾
        if max(height, width) > max_dimension:
            if height > width:
                new_height = max_dimension
                new_width = int(width * max_dimension / height)
            else:
                new_width = max_dimension
                new_height = int(height * max_dimension / width)
            
            logger.info(f"ç¼©æ”¾å›¾åƒ: {width}x{height} -> {new_width}x{new_height}")
            resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # é‡Šæ”¾åŸå›¾åƒå†…å­˜
            del image
            gc.collect()
            
            return resized_image
        
        return image
    
    def compare_images(self, image1_path: str, image2_path: str, 
                      output_dir: str = "reports") -> ComparisonResult:
        """
        æ¯”è¾ƒä¸¤å¼ å›¾ç‰‡çš„ç›¸ä¼¼åº¦
        
        Args:
            image1_path: ç¬¬ä¸€å¼ å›¾ç‰‡è·¯å¾„ï¼ˆç½‘é¡µæˆªå›¾ï¼‰
            image2_path: ç¬¬äºŒå¼ å›¾ç‰‡è·¯å¾„ï¼ˆFigmaè®¾è®¡ç¨¿ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æ¯”å¯¹ç»“æœ
        """
        try:
            self._log_memory_usage("å¼€å§‹æ¯”è¾ƒ")
            logger.info(f"å¼€å§‹æ¯”è¾ƒå›¾ç‰‡: {image1_path} vs {image2_path}")
            
            # éªŒè¯æ–‡ä»¶è·¯å¾„
            if not os.path.exists(image1_path):
                raise FileNotFoundError(f"å›¾ç‰‡1ä¸å­˜åœ¨: {image1_path}")
            if not os.path.exists(image2_path):
                raise FileNotFoundError(f"å›¾ç‰‡2ä¸å­˜åœ¨: {image2_path}")
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            if os.path.getsize(image1_path) == 0:
                raise ValueError(f"å›¾ç‰‡1æ–‡ä»¶ä¸ºç©º: {image1_path}")
            if os.path.getsize(image2_path) == 0:
                raise ValueError(f"å›¾ç‰‡2æ–‡ä»¶ä¸ºç©º: {image2_path}")
            
            logger.info(f"å›¾ç‰‡1è·¯å¾„: {os.path.abspath(image1_path)} (å¤§å°: {os.path.getsize(image1_path)} bytes)")
            logger.info(f"å›¾ç‰‡2è·¯å¾„: {os.path.abspath(image2_path)} (å¤§å°: {os.path.getsize(image2_path)} bytes)")
            
            # è¯»å–å›¾ç‰‡
            img1 = cv2.imread(image1_path)
            img2 = cv2.imread(image2_path)
            
            if img1 is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶1: {image1_path} (å¯èƒ½æ ¼å¼ä¸æ”¯æŒæˆ–æ–‡ä»¶æŸå)")
            if img2 is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶2: {image2_path} (å¯èƒ½æ ¼å¼ä¸æ”¯æŒæˆ–æ–‡ä»¶æŸå)")
            
            logger.info(f"å›¾ç‰‡1å°ºå¯¸: {img1.shape}")
            logger.info(f"å›¾ç‰‡2å°ºå¯¸: {img2.shape}")
            
            self._log_memory_usage("å›¾ç‰‡åŠ è½½å®Œæˆ")
            
            # ä¼˜åŒ–å›¾åƒå°ºå¯¸
            img1 = self._optimize_image_size(img1)
            img2 = self._optimize_image_size(img2)
            
            self._log_memory_usage("å›¾ç‰‡ä¼˜åŒ–å®Œæˆ")
            
            # è°ƒæ•´å›¾ç‰‡å°ºå¯¸åˆ°ç›¸åŒå¤§å°
            img1_resized, img2_resized = self._resize_images(img1, img2)
            
            # é‡Šæ”¾åŸå§‹å›¾åƒå†…å­˜
            del img1, img2
            gc.collect()
            
            self._log_memory_usage("å›¾ç‰‡ç¼©æ”¾å®Œæˆ")
            
            # è®¡ç®—å„ç§ç›¸ä¼¼åº¦æŒ‡æ ‡
            similarity_score = self._calculate_similarity(img1_resized, img2_resized)
            mse_score = self._calculate_mse(img1_resized, img2_resized)
            ssim_score = self._calculate_ssim(img1_resized, img2_resized)
            hash_distance = self._calculate_hash_distance(image1_path, image2_path)
            
            self._log_memory_usage("ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆ")
            
            # ç”Ÿæˆå·®å¼‚å›¾åƒï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
            diff_image_path = self._generate_diff_image_optimized(
                img1_resized, img2_resized, output_dir
            )
            
            self._log_memory_usage("å·®å¼‚å›¾åƒç”Ÿæˆå®Œæˆ")
            
            # åˆ†æå·®å¼‚
            analysis = self._analyze_differences(img1_resized, img2_resized)
            
            # é‡Šæ”¾å¤„ç†åçš„å›¾åƒå†…å­˜
            del img1_resized, img2_resized
            gc.collect()
            
            self._log_memory_usage("å·®å¼‚åˆ†æå®Œæˆ")
            
            result = ComparisonResult(
                similarity_score=similarity_score,
                mse_score=mse_score,
                ssim_score=ssim_score,
                hash_distance=hash_distance,
                differences_count=analysis.get('differences_count', 0),
                diff_image_path=diff_image_path,
                analysis=analysis
            )
            
            logger.info(f"å›¾ç‰‡æ¯”è¾ƒå®Œæˆï¼Œç›¸ä¼¼åº¦: {similarity_score:.3f}")
            self._log_memory_usage("æ¯”è¾ƒå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡æ¯”è¾ƒå¤±è´¥: {e}")
            # ç¡®ä¿å†…å­˜æ¸…ç†
            gc.collect()
            raise
    
    def _resize_images(self, img1: np.ndarray, img2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """è°ƒæ•´å›¾ç‰‡å°ºå¯¸åˆ°ç›¸åŒå¤§å°ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        h1, w1 = img1.shape[:2]
        h2, w2 = img2.shape[:2]
        
        # ä½¿ç”¨è¾ƒå°çš„å°ºå¯¸ä»¥èŠ‚çœå†…å­˜
        target_h = min(h1, h2, self.MAX_IMAGE_DIMENSION)
        target_w = min(w1, w2, self.MAX_IMAGE_DIMENSION)
        
        # è°ƒæ•´å°ºå¯¸ä¿æŒå®½é«˜æ¯”
        aspect1 = w1 / h1
        aspect2 = w2 / h2
        
        if aspect1 > 1:  # æ¨ªå‘å›¾ç‰‡
            final_w = target_w
            final_h = int(target_w / max(aspect1, aspect2))
        else:  # çºµå‘å›¾ç‰‡
            final_h = target_h
            final_w = int(target_h * min(aspect1, aspect2))
        
        # ä½¿ç”¨INTER_AREAæ’å€¼ç®—æ³•ï¼Œé€‚åˆç¼©å°å›¾åƒ
        img1_resized = cv2.resize(img1, (final_w, final_h), interpolation=cv2.INTER_AREA)
        img2_resized = cv2.resize(img2, (final_w, final_h), interpolation=cv2.INTER_AREA)
        
        return img1_resized, img2_resized
    
    def _calculate_similarity(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """è®¡ç®—åŸºç¡€ç›¸ä¼¼åº¦ï¼ˆåŸºäºç›´æ–¹å›¾ï¼‰ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        try:
            # è½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´
            hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)
            hsv2 = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)
            
            # ä½¿ç”¨è¾ƒå°çš„binæ•°é‡ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
            hist1 = cv2.calcHist([hsv1], [0, 1, 2], None, [32, 32, 32], [0, 180, 0, 256, 0, 256])
            hist2 = cv2.calcHist([hsv2], [0, 1, 2], None, [32, 32, 32], [0, 180, 0, 256, 0, 256])
            
            # é‡Šæ”¾HSVå›¾åƒå†…å­˜
            del hsv1, hsv2
            gc.collect()
            
            # è®¡ç®—ç›¸å…³æ€§
            correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            
            # é‡Šæ”¾ç›´æ–¹å›¾å†…å­˜
            del hist1, hist2
            gc.collect()
            
            return max(0, correlation)
        except Exception as e:
            logger.error(f"è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            gc.collect()
            return 0.0
    
    def _calculate_mse(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """è®¡ç®—å‡æ–¹è¯¯å·®"""
        mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)
        return mse
    
    def _calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """è®¡ç®—ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            
            # å¦‚æœå›¾åƒå¤ªå¤§ï¼Œè¿›ä¸€æ­¥ç¼©å°ä»¥èŠ‚çœè®¡ç®—æ—¶é—´å’Œå†…å­˜
            if gray1.shape[0] * gray1.shape[1] > 1024 * 1024:  # 1M åƒç´ 
                scale = 0.5
                new_height = int(gray1.shape[0] * scale)
                new_width = int(gray1.shape[1] * scale)
                
                gray1_small = cv2.resize(gray1, (new_width, new_height))
                gray2_small = cv2.resize(gray2, (new_width, new_height))
                
                del gray1, gray2
                gc.collect()
                
                gray1, gray2 = gray1_small, gray2_small
            
            # è®¡ç®—SSIM
            from skimage.metrics import structural_similarity
            ssim = structural_similarity(gray1, gray2)
            
            # é‡Šæ”¾ç°åº¦å›¾åƒå†…å­˜
            del gray1, gray2
            gc.collect()
            
            return ssim
        except Exception as e:
            logger.error(f"è®¡ç®—SSIMå¤±è´¥: {e}")
            gc.collect()
            return 0.0
    
    def _calculate_hash_distance(self, img1_path: str, img2_path: str) -> int:
        """è®¡ç®—æ„ŸçŸ¥å“ˆå¸Œè·ç¦»"""
        img1 = Image.open(img1_path)
        img2 = Image.open(img2_path)
        
        hash1 = imagehash.phash(img1)
        hash2 = imagehash.phash(img2)
        
        return hash1 - hash2
    
    def _generate_diff_image(self, img1: np.ndarray, img2: np.ndarray, 
                           output_dir: str) -> str:
        """ç”Ÿæˆå·®å¼‚å›¾åƒ"""
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            # è®¡ç®—å·®å¼‚
            diff = cv2.absdiff(img1, img2)
            
            # å¢å¼ºå·®å¼‚æ˜¾ç¤º
            diff_enhanced = cv2.multiply(diff, 3)
            
            # åˆ›å»ºå¯¹æ¯”å›¾åƒ
            height, width = img1.shape[:2]
            comparison = np.zeros((height, width * 3, 3), dtype=np.uint8)
            
            # æ‹¼æ¥åŸå›¾ã€ç›®æ ‡å›¾å’Œå·®å¼‚å›¾
            comparison[:, :width] = img1
            comparison[:, width:2*width] = img2
            comparison[:, 2*width:] = diff_enhanced
            
            # æ·»åŠ æ ‡ç­¾
            comparison = self._add_labels(comparison, ['ç½‘é¡µæˆªå›¾', 'Figmaè®¾è®¡ç¨¿', 'å·®å¼‚å¯¹æ¯”'])
            
            # ä¿å­˜å·®å¼‚å›¾åƒ
            diff_path = os.path.join(output_dir, f"diff_comparison_{int(time.time())}.png")
            cv2.imwrite(diff_path, comparison)
            
            return diff_path
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå·®å¼‚å›¾åƒå¤±è´¥: {e}")
            raise
    
    def _generate_diff_image_optimized(self, img1: np.ndarray, img2: np.ndarray, 
                           output_dir: str) -> str:
        """ç”Ÿæˆå·®å¼‚å›¾åƒ (ä¼˜åŒ–å†…å­˜ä½¿ç”¨)"""
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            height, width = img1.shape[:2]
            
            # ä¸ºäº†èŠ‚çœå†…å­˜ï¼Œä¸åˆ›å»ºå®Œæ•´çš„ä¸‰è”å›¾ï¼Œè€Œæ˜¯åˆ†åˆ«ä¿å­˜
            diff_timestamp = int(time.time())
            
            # è®¡ç®—å¹¶ä¿å­˜å·®å¼‚å›¾
            diff = cv2.absdiff(img1, img2)
            diff_enhanced = cv2.multiply(diff, 3)
            
            # ä¿å­˜å•ç‹¬çš„å·®å¼‚å›¾åƒ
            diff_only_path = os.path.join(output_dir, f"diff_only_{diff_timestamp}.png")
            cv2.imwrite(diff_only_path, diff_enhanced)
            
            # åˆ›å»ºä¸€ä¸ªè¾ƒå°çš„å¯¹æ¯”å›¾åƒï¼ˆç¼©å°å°ºå¯¸ä»¥èŠ‚çœå†…å­˜ï¼‰
            scale_factor = min(1.0, 800 / max(width, height))  # é™åˆ¶æœ€å¤§å®½åº¦800px
            if scale_factor < 1.0:
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                
                img1_small = cv2.resize(img1, (new_width, new_height))
                img2_small = cv2.resize(img2, (new_width, new_height))
                diff_small = cv2.resize(diff_enhanced, (new_width, new_height))
                
                # é‡Šæ”¾åŸå§‹å·®å¼‚å›¾åƒå†…å­˜
                del diff, diff_enhanced
                gc.collect()
            else:
                img1_small = img1.copy()
                img2_small = img2.copy()
                diff_small = diff_enhanced.copy()
                del diff, diff_enhanced
                gc.collect()
            
            # åˆ›å»ºå¯¹æ¯”å›¾åƒï¼ˆä½¿ç”¨è¾ƒå°çš„å°ºå¯¸ï¼‰
            small_height, small_width = img1_small.shape[:2]
            comparison = np.zeros((small_height, small_width * 3, 3), dtype=np.uint8)
            
            # æ‹¼æ¥å›¾åƒ
            comparison[:, :small_width] = img1_small
            comparison[:, small_width:2*small_width] = img2_small
            comparison[:, 2*small_width:] = diff_small
            
            # é‡Šæ”¾ä¸´æ—¶å›¾åƒå†…å­˜
            del img1_small, img2_small, diff_small
            gc.collect()
            
            # æ·»åŠ æ ‡ç­¾
            comparison = self._add_labels(comparison, ['ç½‘é¡µæˆªå›¾', 'Figmaè®¾è®¡ç¨¿', 'å·®å¼‚å¯¹æ¯”'])
            
            # ä¿å­˜å¯¹æ¯”å›¾åƒ
            comparison_path = os.path.join(output_dir, f"diff_comparison_{diff_timestamp}.png")
            cv2.imwrite(comparison_path, comparison)
            
            # é‡Šæ”¾å¯¹æ¯”å›¾åƒå†…å­˜
            del comparison
            gc.collect()
            
            return comparison_path
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå·®å¼‚å›¾åƒå¤±è´¥: {e}")
            # ç¡®ä¿å†…å­˜æ¸…ç†
            gc.collect()
            raise
    
    def _add_labels(self, image: np.ndarray, labels: List[str]) -> np.ndarray:
        """ä¸ºå›¾åƒæ·»åŠ æ ‡ç­¾"""
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒä»¥ä¾¿æ·»åŠ æ–‡å­—
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(pil_image)
            
            # å°è¯•åŠ è½½å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å­—ä½“
            try:
                font = ImageFont.truetype("arial.ttf", 24)
            except:
                font = ImageFont.load_default()
            
            width = image.shape[1] // 3
            for i, label in enumerate(labels):
                x = i * width + 10
                y = 10
                draw.text((x, y), label, fill=(255, 255, 255), font=font)
                draw.text((x+1, y+1), label, fill=(0, 0, 0), font=font)  # é˜´å½±æ•ˆæœ
            
            # è½¬æ¢å›OpenCVæ ¼å¼
            return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
        except Exception as e:
            logger.warning(f"æ·»åŠ æ ‡ç­¾å¤±è´¥ï¼Œè¿”å›åŸå›¾åƒ: {e}")
            return image
    
    def _analyze_differences(self, img1: np.ndarray, img2: np.ndarray) -> Dict:
        """åˆ†æå›¾åƒå·®å¼‚ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
            
            # è®¡ç®—å·®å¼‚
            diff = cv2.absdiff(gray1, gray2)
            
            # é‡Šæ”¾ç°åº¦å›¾åƒå†…å­˜
            del gray1, gray2
            gc.collect()
            
            # åº”ç”¨é˜ˆå€¼å¾—åˆ°äºŒå€¼åŒ–å·®å¼‚å›¾
            _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)
            
            # é‡Šæ”¾å·®å¼‚å›¾åƒå†…å­˜
            del diff
            gc.collect()
            
            # æŸ¥æ‰¾è½®å»“ï¼ˆå·®å¼‚åŒºåŸŸï¼‰
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # é‡Šæ”¾é˜ˆå€¼å›¾åƒå†…å­˜
            del thresh
            gc.collect()
            
            # åˆ†æå·®å¼‚åŒºåŸŸ
            differences_count = len(contours)
            total_diff_area = sum(cv2.contourArea(contour) for contour in contours)
            total_area = img1.shape[0] * img1.shape[1]
            diff_percentage = (total_diff_area / total_area) * 100
            
            # é¢œè‰²å·®å¼‚åˆ†æï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
            color_diff = self._analyze_color_differences_optimized(img1, img2)
            
            analysis = {
                'differences_count': differences_count,
                'total_diff_area': int(total_diff_area),
                'diff_percentage': round(diff_percentage, 2),
                'color_analysis': color_diff,
                'image_dimensions': {
                    'width': img1.shape[1],
                    'height': img1.shape[0]
                }
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"åˆ†æå·®å¼‚å¤±è´¥: {e}")
            gc.collect()
            return {'error': str(e)}
    
    def _analyze_color_differences_optimized(self, img1: np.ndarray, img2: np.ndarray) -> Dict:
        """åˆ†æé¢œè‰²å·®å¼‚ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        try:
            # å¯¹å¤§å›¾åƒè¿›è¡Œé‡‡æ ·ä»¥å‡å°‘è®¡ç®—é‡
            if img1.shape[0] * img1.shape[1] > 500000:  # 50ä¸‡åƒç´ 
                # éšæœºé‡‡æ ·
                step = max(1, int(np.sqrt(img1.shape[0] * img1.shape[1] / 100000)))  # é‡‡æ ·åˆ°çº¦10ä¸‡åƒç´ 
                sampled_img1 = img1[::step, ::step]
                sampled_img2 = img2[::step, ::step]
            else:
                sampled_img1 = img1
                sampled_img2 = img2
            
            # è®¡ç®—å¹³å‡é¢œè‰²
            mean_color1 = np.mean(sampled_img1, axis=(0, 1))
            mean_color2 = np.mean(sampled_img2, axis=(0, 1))
            
            # è®¡ç®—é¢œè‰²å·®å¼‚
            color_diff = np.abs(mean_color1 - mean_color2)
            
            result = {
                'image1_mean_color': mean_color1.tolist(),
                'image2_mean_color': mean_color2.tolist(),
                'color_difference': color_diff.tolist(),
                'max_color_diff': float(np.max(color_diff))
            }
            
            # é‡Šæ”¾é‡‡æ ·å›¾åƒå†…å­˜ï¼ˆå¦‚æœæ˜¯å¤åˆ¶çš„ï¼‰
            if sampled_img1 is not img1:
                del sampled_img1, sampled_img2
                gc.collect()
            
            return result
            
        except Exception as e:
            logger.error(f"é¢œè‰²åˆ†æå¤±è´¥: {e}")
            gc.collect()
            return {'error': str(e)}
    
    def generate_report(self, result: ComparisonResult, output_path: str) -> str:
        """ç”Ÿæˆæ¯”å¯¹æŠ¥å‘Š"""
        try:
            # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            def convert_numpy_types(obj):
                """é€’å½’è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
                if isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, dict):
                    return {key: convert_numpy_types(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                else:
                    return obj
            
            report_data = {
                'comparison_result': {
                    'similarity_score': float(result.similarity_score),
                    'mse_score': float(result.mse_score),
                    'ssim_score': float(result.ssim_score),
                    'hash_distance': int(result.hash_distance),
                    'differences_count': int(result.differences_count),
                    'overall_rating': self._get_overall_rating(result.similarity_score)
                },
                'analysis': convert_numpy_types(result.analysis),
                'diff_image_path': result.diff_image_path,
                'recommendations': self._generate_recommendations(result)
            }
            
            # ä¿å­˜JSONæŠ¥å‘Š
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æ¯”å¯¹æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            raise
    
    def _get_overall_rating(self, similarity_score: float) -> str:
        """è·å–æ•´ä½“è¯„çº§"""
        if similarity_score >= 0.9:
            return "ä¼˜ç§€ (Excellent)"
        elif similarity_score >= 0.8:
            return "è‰¯å¥½ (Good)"
        elif similarity_score >= 0.7:
            return "ä¸€èˆ¬ (Fair)"
        elif similarity_score >= 0.6:
            return "è¾ƒå·® (Poor)"
        else:
            return "å¾ˆå·® (Very Poor)"
    
    def _generate_recommendations(self, result: ComparisonResult) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        if result.similarity_score < 0.8:
            recommendations.append("å»ºè®®æ£€æŸ¥é¡µé¢å¸ƒå±€æ˜¯å¦ä¸è®¾è®¡ç¨¿ä¸€è‡´")
        
        if result.analysis.get('color_analysis', {}).get('max_color_diff', 0) > 50:
            recommendations.append("å»ºè®®æ£€æŸ¥é¢œè‰²é…ç½®ï¼Œå­˜åœ¨è¾ƒå¤§é¢œè‰²å·®å¼‚")
        
        if result.analysis.get('diff_percentage', 0) > 20:
            recommendations.append("å»ºè®®æ£€æŸ¥é¡µé¢å…ƒç´ ä½ç½®ï¼Œå­˜åœ¨è¾ƒå¤§å¸ƒå±€å·®å¼‚")
        
        if result.hash_distance > 10:
            recommendations.append("å»ºè®®æ£€æŸ¥å›¾åƒå†…å®¹ï¼Œç»“æ„å·®å¼‚è¾ƒå¤§")
        
        if not recommendations:
            recommendations.append("é¡µé¢å®ç°ä¸è®¾è®¡ç¨¿åŒ¹é…åº¦è¾ƒé«˜ï¼Œæ— é‡å¤§é—®é¢˜")
        
        return recommendations
    
    def generate_html_report(self, result: ComparisonResult, output_path: str) -> str:
        """
        ç”ŸæˆHTMLè§†è§‰å¯¹æ¯”æŠ¥å‘Š
        
        Args:
            result: æ¯”å¯¹ç»“æœ
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            HTMLæŠ¥å‘Šè·¯å¾„
        """
        try:
            # ç”ŸæˆHTMLå†…å®¹
            html_content = self._generate_html_content(result)
            
            # å†™å…¥æ–‡ä»¶
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"HTMLæ¯”å¯¹æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"ç”ŸæˆHTMLæŠ¥å‘Šå¤±è´¥: {e}")
            raise
    
    def _generate_html_content(self, result: ComparisonResult) -> str:
        """ç”ŸæˆHTMLå†…å®¹"""
        
        # è½¬æ¢å·®å¼‚å›¾åƒè·¯å¾„
        diff_image_url = convert_diff_image_path(result.diff_image_path) if result.diff_image_path else ""
        
        # ç”Ÿæˆè¯„çº§æ ·å¼
        rating_class = self._get_rating_class(result.similarity_score)
        
        # ç”Ÿæˆæ¨èå»ºè®®HTML
        recommendations = self._generate_recommendations(result)
        recommendations_html = self._generate_recommendations_html(recommendations)
        
        # ç”Ÿæˆåˆ†æè¯¦æƒ…HTML
        analysis_html = self._generate_analysis_html(result.analysis)
        
        # HTMLæ¨¡æ¿
        html_template = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è§†è§‰å¯¹æ¯”æŠ¥å‘Š</title>
    <style>
        {self._get_css_styles()}
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1>ğŸ¨ è§†è§‰å¯¹æ¯”æŠ¥å‘Š</h1>
            <div class="summary-cards">
                <div class="card similarity">
                    <h3>ç›¸ä¼¼åº¦</h3>
                    <div class="number {rating_class}">{result.similarity_score:.3f}</div>
                    <div class="rating">{self._get_overall_rating(result.similarity_score)}</div>
                </div>
                <div class="card mse">
                    <h3>å‡æ–¹è¯¯å·®</h3>
                    <div class="number">{result.mse_score:.2f}</div>
                </div>
                <div class="card ssim">
                    <h3>ç»“æ„ç›¸ä¼¼æ€§</h3>
                    <div class="number">{result.ssim_score:.3f}</div>
                </div>
                <div class="card differences">
                    <h3>å·®å¼‚ç‚¹æ•°</h3>
                    <div class="number">{result.differences_count}</div>
                </div>
            </div>
        </header>
        
        <section class="diff-image-section">
            <h2>ğŸ“· å·®å¼‚å¯¹æ¯”å›¾</h2>
            {f'<div class="diff-image-container"><img src="{diff_image_url}" alt="å·®å¼‚å¯¹æ¯”å›¾" class="diff-image" onclick="showFullscreen(this)"></div>' if diff_image_url and ensure_file_exists(result.diff_image_path) else '<p>å·®å¼‚å›¾åƒä¸å¯ç”¨</p>'}
        </section>
        
        <section class="analysis-section">
            <h2>ğŸ“Š åˆ†æè¯¦æƒ…</h2>
            {analysis_html}
        </section>
        
        <section class="recommendations-section">
            <h2>ğŸ’¡ æ”¹è¿›å»ºè®®</h2>
            {recommendations_html}
        </section>
        
        <footer class="footer">
            <p>æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
        </footer>
    </div>
    
    <script>
        {self._get_javascript()}
    </script>
</body>
</html>
"""
        
        return html_template
    
    def _get_rating_class(self, similarity_score: float) -> str:
        """è·å–è¯„çº§CSSç±»"""
        if similarity_score >= 0.9:
            return "excellent"
        elif similarity_score >= 0.8:
            return "good"
        elif similarity_score >= 0.7:
            return "fair"
        elif similarity_score >= 0.6:
            return "poor"
        else:
            return "very-poor"
    
    def _generate_recommendations_html(self, recommendations: List[str]) -> str:
        """ç”Ÿæˆæ¨èå»ºè®®HTML"""
        if not recommendations:
            return "<p>æ— å»ºè®®</p>"
        
        html_parts = ["<ul class='recommendations-list'>"]
        for recommendation in recommendations:
            html_parts.append(f"<li>{recommendation}</li>")
        html_parts.append("</ul>")
        
        return "\n".join(html_parts)
    
    def _generate_analysis_html(self, analysis: Dict) -> str:
        """ç”Ÿæˆåˆ†æè¯¦æƒ…HTML"""
        if not analysis or "error" in analysis:
            return "<p>åˆ†ææ•°æ®ä¸å¯ç”¨</p>"
        
        html_parts = ["<div class='analysis-grid'>"]
        
        # å·®å¼‚ç»Ÿè®¡
        html_parts.append(f"""
        <div class="analysis-item">
            <h3>å·®å¼‚ç»Ÿè®¡</h3>
            <div class="stat-grid">
                <div class="stat">
                    <label>å·®å¼‚åŒºåŸŸæ•°é‡:</label>
                    <span>{analysis.get('differences_count', 0)}</span>
                </div>
                <div class="stat">
                    <label>å·®å¼‚é¢ç§¯:</label>
                    <span>{analysis.get('total_diff_area', 0)} åƒç´ </span>
                </div>
                <div class="stat">
                    <label>å·®å¼‚ç™¾åˆ†æ¯”:</label>
                    <span>{analysis.get('diff_percentage', 0)}%</span>
                </div>
            </div>
        </div>
        """)
        
        # å›¾åƒä¿¡æ¯
        dimensions = analysis.get('image_dimensions', {})
        html_parts.append(f"""
        <div class="analysis-item">
            <h3>å›¾åƒä¿¡æ¯</h3>
            <div class="stat-grid">
                <div class="stat">
                    <label>å®½åº¦:</label>
                    <span>{dimensions.get('width', 0)} px</span>
                </div>
                <div class="stat">
                    <label>é«˜åº¦:</label>
                    <span>{dimensions.get('height', 0)} px</span>
                </div>
            </div>
        </div>
        """)
        
        # é¢œè‰²åˆ†æ
        color_analysis = analysis.get('color_analysis', {})
        if color_analysis and "error" not in color_analysis:
            max_color_diff = color_analysis.get('max_color_diff', 0)
            html_parts.append(f"""
            <div class="analysis-item">
                <h3>é¢œè‰²åˆ†æ</h3>
                <div class="stat-grid">
                    <div class="stat">
                        <label>æœ€å¤§é¢œè‰²å·®å¼‚:</label>
                        <span>{max_color_diff:.2f}</span>
                    </div>
                </div>
            </div>
            """)
        
        html_parts.append("</div>")
        
        return "\n".join(html_parts)
    
    def _get_css_styles(self) -> str:
        """è·å–CSSæ ·å¼"""
        return """
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .header {
            background: white;
            border-radius: 10px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            text-align: center;
            margin-bottom: 30px;
            color: #2c3e50;
        }
        
        .summary-cards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
        }
        
        .card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            border-left: 4px solid #ddd;
        }
        
        .card.similarity { border-left-color: #3498db; }
        .card.mse { border-left-color: #e74c3c; }
        .card.ssim { border-left-color: #27ae60; }
        .card.differences { border-left-color: #f39c12; }
        
        .card h3 {
            margin-bottom: 10px;
            color: #666;
            font-size: 14px;
        }
        
        .card .number {
            font-size: 24px;
            font-weight: bold;
            color: #2c3e50;
        }
        
        .card .number.excellent { color: #27ae60; }
        .card .number.good { color: #2ecc71; }
        .card .number.fair { color: #f39c12; }
        .card .number.poor { color: #e67e22; }
        .card .number.very-poor { color: #e74c3c; }
        
        .card .rating {
            font-size: 12px;
            color: #666;
            margin-top: 5px;
        }
        
        .diff-image-section,
        .analysis-section,
        .recommendations-section {
            background: white;
            border-radius: 10px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .diff-image-container {
            text-align: center;
        }
        
        .diff-image {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            cursor: pointer;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .analysis-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
        }
        
        .analysis-item {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 6px;
        }
        
        .analysis-item h3 {
            margin-bottom: 15px;
            color: #2c3e50;
        }
        
        .stat-grid {
            display: grid;
            gap: 10px;
        }
        
        .stat {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .stat label {
            font-weight: bold;
            color: #666;
        }
        
        .stat span {
            color: #2c3e50;
        }
        
        .recommendations-list {
            list-style: none;
            padding: 0;
        }
        
        .recommendations-list li {
            background: #f8f9fa;
            padding: 10px 15px;
            margin-bottom: 10px;
            border-radius: 5px;
            border-left: 4px solid #3498db;
        }
        
        .footer {
            text-align: center;
            padding: 20px;
            color: #666;
            font-size: 14px;
        }
        
        h2 {
            color: #2c3e50;
            margin-bottom: 20px;
        }
        
        /* å…¨å±æ˜¾ç¤ºæ ·å¼ */
        .fullscreen-modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.8);
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 1000;
            cursor: pointer;
        }
        
        .fullscreen-modal img {
            max-width: 90%;
            max-height: 90%;
            border-radius: 8px;
        }
        """
    
    def _get_javascript(self) -> str:
        """è·å–JavaScriptä»£ç """
        return """
        function showFullscreen(img) {
            const modal = document.createElement('div');
            modal.className = 'fullscreen-modal';
            
            const modalImg = document.createElement('img');
            modalImg.src = img.src;
            modalImg.alt = img.alt;
            
            modal.appendChild(modalImg);
            document.body.appendChild(modal);
            
            modal.onclick = () => document.body.removeChild(modal);
            
            // ESCé”®å…³é—­
            const handleEsc = (e) => {
                if (e.key === 'Escape' && document.body.contains(modal)) {
                    document.body.removeChild(modal);
                    document.removeEventListener('keydown', handleEsc);
                }
            };
            document.addEventListener('keydown', handleEsc);
        }
        """ 